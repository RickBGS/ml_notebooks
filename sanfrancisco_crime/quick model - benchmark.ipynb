{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# modeling\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 21, 21, ..., 16, 35, 12])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def describe_categorical(X):\n",
    "    print(X[X.columns[X.dtypes == 'object']].describe())\n",
    "\n",
    "def get_original_datasets(idx):\n",
    "    global combined\n",
    "    \n",
    "    train0 = pd.read_csv('data/train.csv')\n",
    "    targets = train0.Category\n",
    "    train = combined.head(idx)\n",
    "    test = combined.iloc[idx:]\n",
    "    \n",
    "    return train, test, targets\n",
    "\n",
    "def combined_dataset():\n",
    "    train = pd.read_csv(\"data/train.csv\")\n",
    "    test = pd.read_csv(\"data/test.csv\")\n",
    "    targets = train.Category\n",
    "    train.drop('Category', 1, inplace=True)\n",
    "    combined = train.append(test)\n",
    "    combined.reset_index(inplace=True)\n",
    "    combined.drop('index', inplace=True, axis=1)\n",
    "    \n",
    "    return combined, train.shape[0], targets\n",
    "\n",
    "combined, idx, targets = combined_dataset()\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined['event']=1\n",
    "combined['Dates'] = pd.to_datetime(combined['Dates'])\n",
    "combined['year'] = combined['Dates'].apply(lambda x: x.year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined['Hour'] = combined['Dates'].map(lambda x: x.hour)\n",
    "combined['Month'] = combined['Dates'].map(lambda x: x.month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extractStreetType(x):\n",
    "    types = r\"AV|BL|CR|CT|DR|EX|HWY|HY|LN|PL|PZ|RD|ST|TR|WY|WAY\"\n",
    "    return re.search(types, x, flags=re.IGNORECASE).group()\n",
    "    \n",
    "combined['StreetType'] = combined.Address.apply(extractStreetType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def day_of_week():\n",
    "    global combined\n",
    "    dayofweek_dummies = pd.get_dummies(combined['DayOfWeek'],prefix='DayOfWeek')\n",
    "    combined = pd.concat([combined,dayofweek_dummies],axis=1)\n",
    "    combined.drop('DayOfWeek', inplace=True, axis=1)\n",
    "    \n",
    "day_of_week()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def street_type():\n",
    "    global combined\n",
    "    streettype_dummies = pd.get_dummies(combined['StreetType'],prefix='StreetType')\n",
    "    combined = pd.concat([combined,streettype_dummies],axis=1)\n",
    "    combined.drop('StreetType', inplace=True, axis=1)\n",
    "    combined.drop('Address', inplace=True, axis=1)\n",
    "street_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pd_district():\n",
    "    global combined\n",
    "    pd_district_dummies = pd.get_dummies(combined['PdDistrict'],prefix='PdDistrict')\n",
    "    combined = pd.concat([combined,pd_district_dummies],axis=1)\n",
    "    combined.drop('PdDistrict', inplace=True, axis=1)\n",
    "pd_district()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined.drop(['Id','Descript', 'Resolution', 'Dates'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 ['event', 'year', 'Hour', 'Month']\n",
      "float64 ['X', 'Y', 'DayOfWeek_Friday', 'DayOfWeek_Monday', 'DayOfWeek_Saturday', 'DayOfWeek_Sunday', 'DayOfWeek_Thursday', 'DayOfWeek_Tuesday', 'DayOfWeek_Wednesday', 'StreetType_AV', 'StreetType_BL', 'StreetType_Bl', 'StreetType_CR', 'StreetType_CT', 'StreetType_DR', 'StreetType_EX', 'StreetType_HWY', 'StreetType_HY', 'StreetType_LN', 'StreetType_PL', 'StreetType_PZ', 'StreetType_RD', 'StreetType_ST', 'StreetType_TR', 'StreetType_WAY', 'StreetType_WY', 'PdDistrict_BAYVIEW', 'PdDistrict_CENTRAL', 'PdDistrict_INGLESIDE', 'PdDistrict_MISSION', 'PdDistrict_NORTHERN', 'PdDistrict_PARK', 'PdDistrict_RICHMOND', 'PdDistrict_SOUTHERN', 'PdDistrict_TARAVAL', 'PdDistrict_TENDERLOIN']\n"
     ]
    }
   ],
   "source": [
    "types = combined.columns.to_series().groupby(combined.dtypes).groups\n",
    "for k,v in types.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X                        0\n",
       "Y                        0\n",
       "event                    0\n",
       "year                     0\n",
       "Hour                     0\n",
       "Month                    0\n",
       "DayOfWeek_Friday         0\n",
       "DayOfWeek_Monday         0\n",
       "DayOfWeek_Saturday       0\n",
       "DayOfWeek_Sunday         0\n",
       "DayOfWeek_Thursday       0\n",
       "DayOfWeek_Tuesday        0\n",
       "DayOfWeek_Wednesday      0\n",
       "StreetType_AV            0\n",
       "StreetType_BL            0\n",
       "StreetType_Bl            0\n",
       "StreetType_CR            0\n",
       "StreetType_CT            0\n",
       "StreetType_DR            0\n",
       "StreetType_EX            0\n",
       "StreetType_HWY           0\n",
       "StreetType_HY            0\n",
       "StreetType_LN            0\n",
       "StreetType_PL            0\n",
       "StreetType_PZ            0\n",
       "StreetType_RD            0\n",
       "StreetType_ST            0\n",
       "StreetType_TR            0\n",
       "StreetType_WAY           0\n",
       "StreetType_WY            0\n",
       "PdDistrict_BAYVIEW       0\n",
       "PdDistrict_CENTRAL       0\n",
       "PdDistrict_INGLESIDE     0\n",
       "PdDistrict_MISSION       0\n",
       "PdDistrict_NORTHERN      0\n",
       "PdDistrict_PARK          0\n",
       "PdDistrict_RICHMOND      0\n",
       "PdDistrict_SOUTHERN      0\n",
       "PdDistrict_TARAVAL       0\n",
       "PdDistrict_TENDERLOIN    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test, targets = get_original_datasets(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614634, 40)\n",
      "(263415, 40)\n",
      "(614634,)\n",
      "(263415,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, targets, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergio/anaconda/lib/python3.5/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=True, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=10 ,oob_score=True, random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_train_pred = model.predict(X_train)\n",
    "# y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * uncalibrated classifier trained on 800 datapoints: 14.240 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "clf_probs = model.predict_proba(X_test)\n",
    "score = log_loss(y_test, clf_probs)\n",
    "print(\" * uncalibrated classifier trained on 800 datapoints: %.3f \" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             precision    recall  f1-score   support\n",
      "\n",
      "                      ARSON       0.04      0.03      0.03       451\n",
      "                    ASSAULT       0.19      0.23      0.21     23137\n",
      "                 BAD CHECKS       0.00      0.00      0.00       118\n",
      "                    BRIBERY       0.00      0.00      0.00        84\n",
      "                   BURGLARY       0.14      0.13      0.14     10890\n",
      "         DISORDERLY CONDUCT       0.03      0.03      0.03      1226\n",
      "DRIVING UNDER THE INFLUENCE       0.03      0.02      0.02       701\n",
      "              DRUG/NARCOTIC       0.34      0.41      0.37     16338\n",
      "                DRUNKENNESS       0.00      0.00      0.00      1260\n",
      "               EMBEZZLEMENT       0.02      0.01      0.01       340\n",
      "                  EXTORTION       0.00      0.00      0.00        82\n",
      "            FAMILY OFFENSES       0.05      0.03      0.04       144\n",
      "     FORGERY/COUNTERFEITING       0.13      0.10      0.11      3161\n",
      "                      FRAUD       0.07      0.06      0.07      4929\n",
      "                   GAMBLING       0.00      0.00      0.00        48\n",
      "                 KIDNAPPING       0.04      0.04      0.04       714\n",
      "              LARCENY/THEFT       0.37      0.49      0.42     52146\n",
      "                LIQUOR LAWS       0.10      0.07      0.09       596\n",
      "                  LOITERING       0.21      0.14      0.17       379\n",
      "             MISSING PERSON       0.49      0.47      0.48      7802\n",
      "               NON-CRIMINAL       0.21      0.18      0.19     27775\n",
      "             OTHER OFFENSES       0.26      0.28      0.27     37904\n",
      "    PORNOGRAPHY/OBSCENE MAT       0.00      0.00      0.00         8\n",
      "               PROSTITUTION       0.57      0.59      0.58      2202\n",
      "          RECOVERED VEHICLE       0.06      0.02      0.03       950\n",
      "                    ROBBERY       0.09      0.04      0.06      6883\n",
      "                    RUNAWAY       0.22      0.16      0.18       592\n",
      "            SECONDARY CODES       0.01      0.01      0.01      2930\n",
      "      SEX OFFENSES FORCIBLE       0.22      0.14      0.17      1305\n",
      "  SEX OFFENSES NON FORCIBLE       0.00      0.00      0.00        44\n",
      "            STOLEN PROPERTY       0.02      0.01      0.01      1405\n",
      "                    SUICIDE       0.00      0.00      0.00       145\n",
      "             SUSPICIOUS OCC       0.07      0.04      0.05      9566\n",
      "                       TREA       0.00      0.00      0.00         2\n",
      "                   TRESPASS       0.05      0.03      0.04      2207\n",
      "                  VANDALISM       0.13      0.08      0.10     13483\n",
      "              VEHICLE THEFT       0.45      0.37      0.41     16152\n",
      "                   WARRANTS       0.13      0.10      0.12     12781\n",
      "                WEAPON LAWS       0.15      0.12      0.13      2535\n",
      "\n",
      "                avg / total       0.25      0.27      0.25    263415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "predicted = np.array(model.predict_proba(test))\n",
    "\n",
    "labels = ['Id']\n",
    "for i in model.classes_:\n",
    "    labels.append(i)\n",
    "with open('submissions/sn_quick_model_submission.csv', 'wt') as outf:\n",
    "  fo = csv.writer(outf, lineterminator='\\n')\n",
    "  fo.writerow(labels)\n",
    "\n",
    "  for i, pred in enumerate(predicted):\n",
    "    fo.writerow([i] + list(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
